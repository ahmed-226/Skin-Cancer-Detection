{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "136b5d61",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466db3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mahotas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bc5f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_dir = '/kaggle/input/skin-cancer-binary-classification-dataset/Skin_Data'\n",
    "cancer_train_dir = os.path.join(data_dir, 'Cancer', 'Training')\n",
    "cancer_test_dir = os.path.join(data_dir, 'Cancer', 'Testing')\n",
    "non_cancer_train_dir = os.path.join(data_dir, 'Non_Cancer', 'Training')\n",
    "non_cancer_test_dir = os.path.join(data_dir, 'Non_Cancer', 'Testing')\n",
    "\n",
    "cancer_train_files = [os.path.join(cancer_train_dir, f) for f in os.listdir(cancer_train_dir) if f.lower().endswith(('.jpg', '.jpeg'))]\n",
    "non_cancer_train_files = [os.path.join(non_cancer_train_dir, f) for f in os.listdir(non_cancer_train_dir) if f.lower().endswith(('.jpg', '.jpeg'))]\n",
    "\n",
    "cancer_test_files = [os.path.join(cancer_test_dir, f) for f in os.listdir(cancer_test_dir) if f.lower().endswith(('.jpg', '.jpeg'))]\n",
    "non_cancer_test_files = [os.path.join(non_cancer_test_dir, f) for f in os.listdir(non_cancer_test_dir) if f.lower().endswith(('.jpg', '.jpeg'))]\n",
    "\n",
    "train_labels_cancer = [1] * len(cancer_train_files)\n",
    "train_labels_non_cancer = [0] * len(non_cancer_train_files)\n",
    "test_labels_cancer = [1] * len(cancer_test_files)\n",
    "test_labels_non_cancer = [0] * len(non_cancer_test_files)\n",
    "\n",
    "train_files = cancer_train_files + non_cancer_train_files\n",
    "train_labels = train_labels_cancer + train_labels_non_cancer\n",
    "test_files = cancer_test_files + non_cancer_test_files\n",
    "test_labels = test_labels_cancer + test_labels_non_cancer\n",
    "\n",
    "print(\"Number of Cancer training files:\", len(cancer_train_files))\n",
    "print(\"Number of Non-Cancer training files:\", len(non_cancer_train_files))\n",
    "print(\"Number of Cancer testing files:\", len(cancer_test_files))\n",
    "print(\"Number of Non-Cancer testing files:\", len(non_cancer_test_files))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Example Cancer training image\n",
    "plt.subplot(2, 2, 1)\n",
    "if cancer_train_files:\n",
    "    img = mpimg.imread(cancer_train_files[1])\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Example Cancer Training Image\")\n",
    "    plt.axis('off')\n",
    "else:\n",
    "    plt.text(0.5, 0.5, \"No Cancer training files\", ha='center', va='center')\n",
    "    plt.axis('off')\n",
    "\n",
    "# Example Non-Cancer training image\n",
    "plt.subplot(2, 2, 2)\n",
    "if non_cancer_train_files:\n",
    "    img = mpimg.imread(non_cancer_train_files[0])\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Example Non-Cancer Training Image\")\n",
    "    plt.axis('off')\n",
    "else:\n",
    "    plt.text(0.5, 0.5, \"No Non-Cancer training files\", ha='center', va='center')\n",
    "    plt.axis('off')\n",
    "\n",
    "# Example Cancer testing image\n",
    "plt.subplot(2, 2, 3)\n",
    "if cancer_test_files:\n",
    "    img = mpimg.imread(cancer_test_files[0])\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Example Cancer Testing Image\")\n",
    "    plt.axis('off')\n",
    "else:\n",
    "    plt.text(0.5, 0.5, \"No Cancer testing files\", ha='center', va='center')\n",
    "    plt.axis('off')\n",
    "\n",
    "# Example Non-Cancer testing image\n",
    "plt.subplot(2, 2, 4)\n",
    "if non_cancer_test_files:\n",
    "    img = mpimg.imread(non_cancer_test_files[0])\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Example Non-Cancer Testing Image\")\n",
    "    plt.axis('off')\n",
    "else:\n",
    "    plt.text(0.5, 0.5, \"No Non-Cancer testing files\", ha='center', va='center')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420f6681",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09086135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_glare(image):\n",
    "    # Convert to HSV color space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    _, s, v = cv2.split(hsv)  # Saturation and Value channels\n",
    "\n",
    "    # Normalize the Value channel\n",
    "    v = cv2.normalize(v, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    # Adaptive thresholding with Otsu's method\n",
    "    _, glare_mask = cv2.threshold(v, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Refine with saturation mask (glare has low saturation)\n",
    "    _, saturation_mask = cv2.threshold(s, 50, 255, cv2.THRESH_BINARY_INV)\n",
    "    glare_mask = cv2.bitwise_and(glare_mask, saturation_mask)\n",
    "\n",
    "    # Dilate and erode to refine the mask\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    glare_mask = cv2.dilate(glare_mask, kernel, iterations=1)\n",
    "    glare_mask = cv2.erode(glare_mask, kernel, iterations=1)\n",
    "\n",
    "    # Inpaint the glare regions\n",
    "    image_no_glare = cv2.inpaint(image, glare_mask, 5, cv2.INPAINT_TELEA)\n",
    "\n",
    "    # Check if glare mask is too large (likely over-segmentation)\n",
    "    mask_area = np.sum(glare_mask == 255)\n",
    "    image_area = image.shape[0] * image.shape[1]\n",
    "    alpha = 0.7  # Default blending factor\n",
    "    if mask_area / image_area > 0.3:  # If glare mask covers more than 30%\n",
    "        alpha = 0.9  # Increase blending to preserve more details\n",
    "\n",
    "    # Blend with the original image\n",
    "    image_no_glare = cv2.addWeighted(image, alpha, image_no_glare, 1 - alpha, 0)\n",
    "\n",
    "    return image_no_glare, glare_mask \n",
    "\n",
    "def remove_hair(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply black-hat morphological operation to detect dark hair\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (17, 17))\n",
    "    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)\n",
    "\n",
    "    # Threshold to create hair mask\n",
    "    _, hair_mask = cv2.threshold(blackhat, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Inpaint the hair regions\n",
    "    inpainted = cv2.inpaint(image, hair_mask, 3, cv2.INPAINT_TELEA)\n",
    "\n",
    "    return inpainted, hair_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb32ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_processed_image(processed_img):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 5, 1)\n",
    "    plt.title(\"Original\")\n",
    "    plt.imshow(cv2.cvtColor(processed_img['original'], cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 5, 2)\n",
    "    plt.title(\"Hair Mask\")\n",
    "    plt.imshow(processed_img['hair_mask'], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 5, 3)\n",
    "    plt.title(\"Hair Removed\")\n",
    "    plt.imshow(cv2.cvtColor(processed_img['hair_removed'], cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 5, 4)\n",
    "    plt.title(\"Glare Mask\")\n",
    "    plt.imshow(processed_img['glare_mask'], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 5, 5)\n",
    "    plt.title(\"All Processed\")\n",
    "    plt.imshow(cv2.cvtColor(processed_img['glare_removed'], cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Additional function to visualize the fully processed image compared to original\n",
    "def visualize_fully_processed(processed_img):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original\")\n",
    "    plt.imshow(cv2.cvtColor(processed_img['original'], cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Fully Processed (Hair & Glare Removed)\")\n",
    "    plt.imshow(cv2.cvtColor(processed_img['glare_removed'], cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d5236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img_path):\n",
    "    # Read image\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"Failed to load {img_path}\")\n",
    "        return None\n",
    "        \n",
    "    # Remove hair\n",
    "    img_hair_removed, hair_mask = remove_hair(img)\n",
    "\n",
    "    # Remove glare on the hair-removed image\n",
    "    img_fully_processed, glare_mask = remove_glare(img_hair_removed)\n",
    "    \n",
    "    return {\n",
    "        'original': img,\n",
    "        'hair_removed': img_hair_removed,\n",
    "        'glare_removed': img_fully_processed,  # This is now both hair and glare removed\n",
    "        'hair_mask': hair_mask,\n",
    "        'glare_mask': glare_mask\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881db74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process sample cancer training images\n",
    "for i, img_path in enumerate(cancer_train_files[:sample_size]):\n",
    "    print(f\"Processing cancer training image {i+1}/{sample_size}\")\n",
    "    processed_img = process_image(img_path)\n",
    "    if processed_img:\n",
    "        processed_train_cancer.append(processed_img)\n",
    "        visualize_processed_image(processed_img)  # Show all steps separately\n",
    "        visualize_fully_processed(processed_img)  # Compare original vs fully processed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a5283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process sample non-cancer training images\n",
    "for i, img_path in enumerate(non_cancer_train_files[:sample_size]):\n",
    "    print(f\"Processing non-cancer training image {i+1}/{sample_size}\")\n",
    "    processed_img = process_image(img_path)\n",
    "    if processed_img:\n",
    "        processed_train_non_cancer.append(processed_img)\n",
    "        visualize_processed_image(processed_img)  # Show all steps separately\n",
    "        visualize_fully_processed(processed_img)  # Compare original vs fully processed\n",
    "\n",
    "# Process sample cancer test images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3358641",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img_path in enumerate(cancer_test_files[:sample_size]):\n",
    "    print(f\"Processing cancer test image {i+1}/{sample_size}\")\n",
    "    processed_img = process_image(img_path)\n",
    "    if processed_img:\n",
    "        processed_test_cancer.append(processed_img)\n",
    "        visualize_processed_image(processed_img)  # Show all steps separately\n",
    "        visualize_fully_processed(processed_img)  # Compare original vs fully processed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fda782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process sample non-cancer test images\n",
    "for i, img_path in enumerate(non_cancer_test_files[:sample_size]):\n",
    "    print(f\"Processing non-cancer test image {i+1}/{sample_size}\")\n",
    "    processed_img = process_image(img_path)\n",
    "    if processed_img:\n",
    "        processed_test_non_cancer.append(processed_img)\n",
    "        visualize_processed_image(processed_img)  # Show all steps separately\n",
    "        visualize_fully_processed(processed_img)  # Compare original vs fully processed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6b9dfa",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034f0622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_histogram(image, mask=None, bins=64):\n",
    "    \"\"\"Extract color histogram (192 features).\"\"\"\n",
    "    if mask is not None:\n",
    "        masked_image = image.copy()\n",
    "        masked_image[mask == 0] = 0\n",
    "    else:\n",
    "        masked_image = image\n",
    "    hist_r = np.histogram(masked_image[:, :, 0].ravel(), bins=bins, range=(0, 256))[0]\n",
    "    hist_g = np.histogram(masked_image[:, :, 1].ravel(), bins=bins, range=(0, 256))[0]\n",
    "    hist_b = np.histogram(masked_image[:, :, 2].ravel(), bins=bins, range=(0, 256))[0]\n",
    "    hist_r = hist_r / (hist_r.sum() + 1e-10)\n",
    "    hist_g = hist_g / (hist_g.sum() + 1e-10)\n",
    "    hist_b = hist_b / (hist_b.sum() + 1e-10)\n",
    "    return np.concatenate([hist_r, hist_g, hist_b])\n",
    "\n",
    "def extract_color_moments(image, mask=None):\n",
    "    \"\"\"Extract color moments in RGB (mean, variance, skewness, kurtosis; 12 features).\"\"\"\n",
    "    if mask is not None:\n",
    "        masked_image = image.copy()\n",
    "        masked_image[mask == 0] = 0\n",
    "    else:\n",
    "        masked_image = image\n",
    "    moments = []\n",
    "    for channel in range(3):\n",
    "        pixels = masked_image[:, :, channel].ravel()\n",
    "        pixels = pixels[pixels != 0] if mask is not None else pixels\n",
    "        if len(pixels) == 0:\n",
    "            moments.extend([0, 0, 0, 0])\n",
    "            continue\n",
    "        mean = np.mean(pixels)\n",
    "        variance = np.var(pixels)\n",
    "        skewness = skew(pixels, bias=False) if variance > 0 else 0\n",
    "        kurt = kurtosis(pixels, bias=False) if variance > 0 else 0\n",
    "        moments.extend([mean, variance, skewness, kurt])\n",
    "    return np.array(moments)\n",
    "\n",
    "def extract_hsv_stats(image, mask=None):\n",
    "    \"\"\"Extract mean and std of HSV channels (6 features).\"\"\"\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    if mask is not None:\n",
    "        masked_hsv = hsv_image.copy()\n",
    "        masked_hsv[mask == 0] = 0\n",
    "    else:\n",
    "        masked_hsv = hsv_image\n",
    "    stats = []\n",
    "    for channel in range(3):\n",
    "        pixels = masked_hsv[:, :, channel].ravel()\n",
    "        pixels = pixels[pixels != 0] if mask is not None else pixels\n",
    "        if len(pixels) == 0:\n",
    "            stats.extend([0, 0])\n",
    "            continue\n",
    "        mean = np.mean(pixels)\n",
    "        std = np.std(pixels)\n",
    "        stats.extend([mean, std])\n",
    "    return np.array(stats)\n",
    "\n",
    "def extract_lab_stats(image, mask=None):\n",
    "    \"\"\"Extract mean and std of LAB channels (6 features).\"\"\"\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "    if mask is not None:\n",
    "        masked_lab = lab_image.copy()\n",
    "        masked_lab[mask == 0] = 0\n",
    "    else:\n",
    "        masked_lab = lab_image\n",
    "    stats = []\n",
    "    for channel in range(3):\n",
    "        pixels = masked_lab[:, :, channel].ravel()\n",
    "        pixels = pixels[pixels != 0] if mask is not None else pixels\n",
    "        if len(pixels) == 0:\n",
    "            stats.extend([0, 0])\n",
    "            continue\n",
    "        mean = np.mean(pixels)\n",
    "        std = np.std(pixels)\n",
    "        stats.extend([mean, std])\n",
    "    return np.array(stats)\n",
    "\n",
    "def extract_haralick_and_stats(image, mask=None, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4]):\n",
    "    \"\"\"Extract Haralick features and intensity stats (mean, std, entropy, kurtosis; 17 features).\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    if mask is not None:\n",
    "        gray[mask == 0] = 0\n",
    "    pixels = gray.ravel()\n",
    "    pixels = pixels[pixels != 0] if mask is not None else pixels\n",
    "    if len(pixels) == 0:\n",
    "        stats = [0, 0, 0, 0]\n",
    "    else:\n",
    "        mean = np.mean(pixels)\n",
    "        std = np.std(pixels)\n",
    "        entropy = -np.sum([(p/pixels.sum()) * np.log2(p/pixels.sum() + 1e-10) \n",
    "                          for p in np.histogram(pixels, bins=256)[0] if p > 0])\n",
    "        kurt = kurtosis(pixels, bias=False) if std > 0 else 0\n",
    "        stats = [mean, std, entropy, kurt]\n",
    "    if mask is not None:\n",
    "        gray_for_glcm = gray.copy()\n",
    "        gray_for_glcm[mask == 0] = 0\n",
    "    else:\n",
    "        gray_for_glcm = gray\n",
    "    gray_for_glcm = gray_for_glcm.astype(np.uint8)\n",
    "    glcm = graycomatrix(gray_for_glcm, distances=distances, angles=angles, \n",
    "                        levels=256, symmetric=True, normed=True)\n",
    "    haralick_features = []\n",
    "    properties = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']\n",
    "    for prop in properties:\n",
    "        prop_values = graycoprops(glcm, prop).mean(axis=1).ravel()\n",
    "        haralick_features.extend(prop_values)\n",
    "    haralick_mahotas = mahotas.features.haralick(gray_for_glcm, return_mean=True)\n",
    "    extra_features = haralick_mahotas[[0, 1, 2, 3, 4, 8]]\n",
    "    return np.concatenate([haralick_features, extra_features, stats])\n",
    "\n",
    "def extract_wavelet_features(image, mask=None, wavelet='db1'):\n",
    "    \"\"\"Extract wavelet transform features (mean and std of coefficients; 6 features).\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    if mask is not None:\n",
    "        gray[mask == 0] = 0\n",
    "    \n",
    "    coeffs = dwt2(gray, wavelet)\n",
    "    cA, (cH, cV, cD) = coeffs  \n",
    "    features = []\n",
    "    for coeff in [cH, cV, cD]:  \n",
    "        pixels = coeff.ravel()\n",
    "        pixels = pixels[pixels != 0] if mask is not None else pixels\n",
    "        if len(pixels) == 0:\n",
    "            features.extend([0, 0])\n",
    "        else:\n",
    "            mean = np.mean(pixels)\n",
    "            std = np.std(pixels)\n",
    "            features.extend([mean, std])\n",
    "    return np.array(features)\n",
    "\n",
    "def extract_lbp(image, mask=None, radius=3, n_points=24):\n",
    "    \"\"\"Extract LBP histogram (26 features).\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    if mask is not None:\n",
    "        gray[mask == 0] = 0\n",
    "    lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), \n",
    "                          range=(0, n_points + 2), density=True)\n",
    "    return hist\n",
    "\n",
    "def extract_hu_moments(image, mask=None):\n",
    "    \"\"\"Extract Hu Moments (7 features).\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    if mask is not None:\n",
    "        gray[mask == 0] = 0\n",
    "    moments = cv2.moments(gray)\n",
    "    hu_moments = cv2.HuMoments(moments).ravel()\n",
    "    hu_moments = -np.sign(hu_moments) * np.log10(np.abs(hu_moments) + 1e-10)\n",
    "    return hu_moments\n",
    "\n",
    "def extract_diameter(image, mask=None):\n",
    "    \"\"\"Extract lesion diameter (1 feature).\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    if mask is None:\n",
    "        _, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    mask = mask.astype(np.uint8)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        diameter = 0\n",
    "    else:\n",
    "        contour = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        if len(contour) >= 5:  \n",
    "            ellipse = cv2.fitEllipse(contour)\n",
    "            diameter = max(ellipse[1])  \n",
    "        else:\n",
    "            \n",
    "            area = cv2.contourArea(contour)\n",
    "            diameter = 2 * np.sqrt(area / np.pi)\n",
    "    return np.array([diameter])\n",
    "\n",
    "def extract_circularity(image, mask=None):\n",
    "    \"\"\"Extract Circularity (1 feature).\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    if mask is None:\n",
    "        _, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    mask = mask.astype(np.uint8)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        circularity = 0\n",
    "    else:\n",
    "        contour = max(contours, key=cv2.contourArea)\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        area = cv2.contourArea(contour)\n",
    "        circularity = (4 * np.pi * area) / (perimeter ** 2 + 1e-10)\n",
    "    return np.array([circularity])\n",
    "\n",
    "def extract_asymmetry_and_border(image, mask=None):\n",
    "    \"\"\"Extract asymmetry and border irregularity (2 features).\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    if mask is None:\n",
    "        _, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    mask = mask.astype(np.uint8)\n",
    "    flipped = cv2.flip(mask, 1)\n",
    "    intersection = cv2.bitwise_and(mask, flipped)\n",
    "    union = cv2.bitwise_or(mask, flipped)\n",
    "    asymmetry_index = 1 - (np.sum(intersection) / (np.sum(union) + 1e-10))\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        border_irregularity = 0\n",
    "    else:\n",
    "        contour = max(contours, key=cv2.contourArea)\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        area = cv2.contourArea(contour)\n",
    "        border_irregularity = perimeter ** 2 / (4 * np.pi * area + 1e-10)\n",
    "    return np.array([asymmetry_index, border_irregularity])\n",
    "\n",
    "def normalize_features(features):\n",
    "    \"\"\"Normalize features to [0, 1] range.\"\"\"\n",
    "    if features.size == 0:\n",
    "        return features\n",
    "    min_val = np.min(features)\n",
    "    max_val = np.max(features)\n",
    "    if max_val == min_val:\n",
    "        return np.zeros_like(features)\n",
    "    return (features - min_val) / (max_val - min_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e776533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_features(image, mask=None):\n",
    "    \"\"\"Extract all features (color, texture, shape) and normalize.\"\"\"\n",
    "    color_hist = extract_color_histogram(image, mask, bins=64)  # 192 features\n",
    "    color_moments = extract_color_moments(image, mask)  # 12 features\n",
    "    hsv_stats = extract_hsv_stats(image, mask)  # 6 features\n",
    "    lab_stats = extract_lab_stats(image, mask)  # 6 features\n",
    "    haralick_stats = extract_haralick_and_stats(image, mask)  # 17 features\n",
    "    wavelet_features = extract_wavelet_features(image, mask)  # 6 features\n",
    "    lbp_hist = extract_lbp(image, mask, radius=3, n_points=24)  # 26 features\n",
    "    hu_moments = extract_hu_moments(image, mask)  # 7 features\n",
    "    diameter = extract_diameter(image, mask)  # 1 feature\n",
    "    circularity = extract_circularity(image, mask)  # 1 feature\n",
    "    asym_border = extract_asymmetry_and_border(image, mask)  # 2 features\n",
    "\n",
    "    features = np.concatenate([\n",
    "        color_hist,\n",
    "        color_moments,\n",
    "        hsv_stats,\n",
    "        lab_stats,\n",
    "        haralick_stats,\n",
    "        wavelet_features,\n",
    "        lbp_hist,\n",
    "        hu_moments,\n",
    "        diameter,\n",
    "        circularity,\n",
    "        asym_border\n",
    "    ])\n",
    "\n",
    "    features = normalize_features(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc1464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_features(train_files, test_files, train_labels, test_labels, output_path='features.npz'):\n",
    "    \"\"\"\n",
    "    Process all images, extract features, and save to NPZ file.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_files: List of training image file paths\n",
    "    - test_files: List of testing image file paths\n",
    "    - train_labels: List of training image labels\n",
    "    - test_labels: List of testing image labels\n",
    "    - output_path: Path to save the NPZ file\n",
    "    \"\"\"\n",
    "    print(f\"Processing {len(train_files)} training images and {len(test_files)} test images...\")\n",
    "    \n",
    "    \n",
    "    train_features = []\n",
    "    test_features = []\n",
    "    \n",
    "    \n",
    "    for i, img_path in enumerate(train_files):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processing training image {i+1}/{len(train_files)}\")\n",
    "        \n",
    "        \n",
    "        processed_img = process_image(img_path)\n",
    "        if processed_img:\n",
    "            \n",
    "            features = extract_all_features(processed_img['glare_removed'])\n",
    "            train_features.append(features)\n",
    "    \n",
    "    \n",
    "    for i, img_path in enumerate(test_files):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processing test image {i+1}/{len(test_files)}\")\n",
    "        \n",
    "        \n",
    "        processed_img = process_image(img_path)\n",
    "        if processed_img:\n",
    "            \n",
    "            features = extract_all_features(processed_img['glare_removed'])\n",
    "            test_features.append(features)\n",
    "    \n",
    "    \n",
    "    train_features = np.array(train_features)\n",
    "    test_features = np.array(test_features)\n",
    "    \n",
    "    np.savez(\n",
    "        output_path,\n",
    "        train_features=train_features,\n",
    "        test_features=test_features,\n",
    "        train_labels=np.array(train_labels[:len(train_features)]),\n",
    "        test_labels=np.array(test_labels[:len(test_features)])\n",
    "    )\n",
    "    \n",
    "    print(f\"Features extracted and saved to {output_path}\")\n",
    "    print(f\"Training features shape: {train_features.shape}\")\n",
    "    print(f\"Testing features shape: {test_features.shape}\")\n",
    "    \n",
    "    return train_features, test_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f0fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = \"kaggle/output/skin_cancer_features.npz\"\n",
    "if not os.path.exists(features_file):\n",
    "    os.makedirs(\"kaggle/output\", exist_ok=True)\n",
    "    \n",
    "    # Extract and save features\n",
    "    train_features, test_features = extract_and_save_features(\n",
    "        train_files, \n",
    "        test_files, \n",
    "        train_labels, \n",
    "        test_labels,\n",
    "        output_path=features_file\n",
    "    )\n",
    "else:\n",
    "    print(f\"Loading features from {features_file}\")\n",
    "    data = np.load(features_file)\n",
    "    train_features = data['train_features']\n",
    "    test_features = data['test_features']\n",
    "    train_labels = data['train_labels']\n",
    "    test_labels = data['test_labels']\n",
    "\n",
    "print(f\"Loaded features: {train_features.shape} training samples, {test_features.shape} test samples\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_features_scaled = scaler.fit_transform(train_features)\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "\n",
    "# Split training data for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_features_scaled, train_labels, test_size=0.2, random_state=42, stratify=train_labels\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(f\"Test set: {test_features_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98793fc",
   "metadata": {},
   "source": [
    "### Models setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99a4e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a06aae9",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f280652f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
