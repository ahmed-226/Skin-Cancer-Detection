{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "136b5d61",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "466db3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mahotas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew ,kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops\n",
    "from pywt import dwt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bc5f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:/Users\\Ayatullah Ahmed/OneDrive/Desktop/archive (11)/Skin_Data'\n",
    "cancer_train_dir = os.path.join(data_dir, 'Cancer', 'Training')\n",
    "cancer_test_dir = os.path.join(data_dir, 'Cancer', 'Testing')\n",
    "non_cancer_train_dir = os.path.join(data_dir, 'Non_Cancer', 'Training')\n",
    "non_cancer_test_dir = os.path.join(data_dir, 'Non_Cancer', 'Testing')\n",
    "\n",
    "cancer_train_files = [os.path.join(cancer_train_dir, f) for f in os.listdir(cancer_train_dir) if f.lower().endswith(('.jpg', '.jpeg'))]\n",
    "non_cancer_train_files = [os.path.join(non_cancer_train_dir, f) for f in os.listdir(non_cancer_train_dir) if f.lower().endswith(('.jpg', '.jpeg'))]\n",
    "\n",
    "cancer_test_files = [os.path.join(cancer_test_dir, f) for f in os.listdir(cancer_test_dir) if f.lower().endswith(('.jpg', '.jpeg'))]\n",
    "non_cancer_test_files = [os.path.join(non_cancer_test_dir, f) for f in os.listdir(non_cancer_test_dir) if f.lower().endswith(('.jpg', '.jpeg'))]\n",
    "\n",
    "train_labels_cancer = [1] * len(cancer_train_files)\n",
    "train_labels_non_cancer = [0] * len(non_cancer_train_files)\n",
    "test_labels_cancer = [1] * len(cancer_test_files)\n",
    "test_labels_non_cancer = [0] * len(non_cancer_test_files)\n",
    "\n",
    "train_files = cancer_train_files + non_cancer_train_files\n",
    "train_labels = train_labels_cancer + train_labels_non_cancer\n",
    "test_files = cancer_test_files + non_cancer_test_files\n",
    "test_labels = test_labels_cancer + test_labels_non_cancer\n",
    "\n",
    "print(\"Number of Cancer training files:\", len(cancer_train_files))\n",
    "print(\"Number of Non-Cancer training files:\", len(non_cancer_train_files))\n",
    "print(\"Number of Cancer testing files:\", len(cancer_test_files))\n",
    "print(\"Number of Non-Cancer testing files:\", len(non_cancer_test_files))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Example Cancer training image\n",
    "plt.subplot(2, 2, 1)\n",
    "if cancer_train_files:\n",
    "    img = mpimg.imread(cancer_train_files[1])\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Example Cancer Training Image\")\n",
    "    plt.axis('off')\n",
    "else:\n",
    "    plt.text(0.5, 0.5, \"No Cancer training files\", ha='center', va='center')\n",
    "    plt.axis('off')\n",
    "\n",
    "# Example Non-Cancer training image\n",
    "plt.subplot(2, 2, 2)\n",
    "if non_cancer_train_files:\n",
    "    img = mpimg.imread(non_cancer_train_files[0])\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Example Non-Cancer Training Image\")\n",
    "    plt.axis('off')\n",
    "else:\n",
    "    plt.text(0.5, 0.5, \"No Non-Cancer training files\", ha='center', va='center')\n",
    "    plt.axis('off')\n",
    "\n",
    "# Example Cancer testing image\n",
    "plt.subplot(2, 2, 3)\n",
    "if cancer_test_files:\n",
    "    img = mpimg.imread(cancer_test_files[0])\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Example Cancer Testing Image\")\n",
    "    plt.axis('off')\n",
    "else:\n",
    "    plt.text(0.5, 0.5, \"No Cancer testing files\", ha='center', va='center')\n",
    "    plt.axis('off')\n",
    "\n",
    "# Example Non-Cancer testing image\n",
    "plt.subplot(2, 2, 4)\n",
    "if non_cancer_test_files:\n",
    "    img = mpimg.imread(non_cancer_test_files[0])\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Example Non-Cancer Testing Image\")\n",
    "    plt.axis('off')\n",
    "else:\n",
    "    plt.text(0.5, 0.5, \"No Non-Cancer testing files\", ha='center', va='center')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420f6681",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09086135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_glare(image):\n",
    "    # Convert to HSV color space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    _, s, v = cv2.split(hsv)  # Saturation and Value channels\n",
    "\n",
    "    # Normalize the Value channel\n",
    "    v = cv2.normalize(v, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    # Adaptive thresholding with Otsu's method\n",
    "    _, glare_mask = cv2.threshold(v, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Refine with saturation mask (glare has low saturation)\n",
    "    _, saturation_mask = cv2.threshold(s, 50, 255, cv2.THRESH_BINARY_INV)\n",
    "    glare_mask = cv2.bitwise_and(glare_mask, saturation_mask)\n",
    "\n",
    "    # Dilate and erode to refine the mask\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    glare_mask = cv2.dilate(glare_mask, kernel, iterations=1)\n",
    "    glare_mask = cv2.erode(glare_mask, kernel, iterations=1)\n",
    "\n",
    "    # Inpaint the glare regions\n",
    "    image_no_glare = cv2.inpaint(image, glare_mask, 5, cv2.INPAINT_TELEA)\n",
    "\n",
    "    # Check if glare mask is too large (likely over-segmentation)\n",
    "    mask_area = np.sum(glare_mask == 255)\n",
    "    image_area = image.shape[0] * image.shape[1]\n",
    "    alpha = 0.7  # Default blending factor\n",
    "    if mask_area / image_area > 0.3:  # If glare mask covers more than 30%\n",
    "        alpha = 0.9  # Increase blending to preserve more details\n",
    "\n",
    "    # Blend with the original image\n",
    "    image_no_glare = cv2.addWeighted(image, alpha, image_no_glare, 1 - alpha, 0)\n",
    "\n",
    "    return image_no_glare, glare_mask \n",
    "\n",
    "def remove_hair(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply black-hat morphological operation to detect dark hair\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (17, 17))\n",
    "    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)\n",
    "\n",
    "    # Threshold to create hair mask\n",
    "    _, hair_mask = cv2.threshold(blackhat, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Inpaint the hair regions\n",
    "    inpainted = cv2.inpaint(image, hair_mask, 3, cv2.INPAINT_TELEA)\n",
    "\n",
    "    return inpainted, hair_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4eb32ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_processed_image(processed_img):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 5, 1)\n",
    "    plt.title(\"Original\")\n",
    "    plt.imshow(cv2.cvtColor(processed_img['original'], cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 5, 2)\n",
    "    plt.title(\"Hair Mask\")\n",
    "    plt.imshow(processed_img['hair_mask'], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 5, 3)\n",
    "    plt.title(\"Hair Removed\")\n",
    "    plt.imshow(cv2.cvtColor(processed_img['hair_removed'], cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 5, 4)\n",
    "    plt.title(\"Glare Mask\")\n",
    "    plt.imshow(processed_img['glare_mask'], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 5, 5)\n",
    "    plt.title(\"All Processed\")\n",
    "    plt.imshow(cv2.cvtColor(processed_img['glare_removed'], cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Additional function to visualize the fully processed image compared to original\n",
    "def visualize_fully_processed(processed_img):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original\")\n",
    "    plt.imshow(cv2.cvtColor(processed_img['original'], cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Fully Processed (Hair & Glare Removed)\")\n",
    "    plt.imshow(cv2.cvtColor(processed_img['glare_removed'], cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42d5236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img_path):\n",
    "    # Read image\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"Failed to load {img_path}\")\n",
    "        return None\n",
    "        \n",
    "    # Remove hair\n",
    "    img_hair_removed, hair_mask = remove_hair(img)\n",
    "\n",
    "    # Remove glare on the hair-removed image\n",
    "    img_fully_processed, glare_mask = remove_glare(img_hair_removed)\n",
    "    \n",
    "    return {\n",
    "        'original': img,\n",
    "        'hair_removed': img_hair_removed,\n",
    "        'glare_removed': img_fully_processed,  # This is now both hair and glare removed\n",
    "        'hair_mask': hair_mask,\n",
    "        'glare_mask': glare_mask\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881db74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process sample cancer training images\n",
    "sample_size = min(10, len(cancer_train_files))\n",
    "processed_train_cancer=[]\n",
    "for i, img_path in enumerate(cancer_train_files[:sample_size]):\n",
    "    print(f\"Processing cancer training image {i+1}/{sample_size}\")\n",
    "    processed_img = process_image(img_path)\n",
    "    if processed_img:\n",
    "        processed_train_cancer.append(processed_img)\n",
    "        visualize_processed_image(processed_img)  # Show all steps separately\n",
    "        visualize_fully_processed(processed_img)  # Compare original vs fully processed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a5283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process sample non-cancer training images\n",
    "for i, img_path in enumerate(non_cancer_train_files[:sample_size]):\n",
    "    processed_train_non_cancer=[]\n",
    "    print(f\"Processing non-cancer training image {i+1}/{sample_size}\")\n",
    "    processed_img = process_image(img_path)\n",
    "    if processed_img:\n",
    "        processed_train_non_cancer.append(processed_img)\n",
    "        visualize_processed_image(processed_img)  # Show all steps separately\n",
    "        visualize_fully_processed(processed_img)  # Compare original vs fully processed\n",
    "\n",
    "# Process sample cancer test images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3358641",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img_path in enumerate(cancer_test_files[:sample_size]):\n",
    "    processed_test_cancer=[]\n",
    "    print(f\"Processing cancer test image {i+1}/{sample_size}\")\n",
    "    processed_img = process_image(img_path)\n",
    "    if processed_img:\n",
    "        processed_test_cancer.append(processed_img)\n",
    "        visualize_processed_image(processed_img)  # Show all steps separately\n",
    "        visualize_fully_processed(processed_img)  # Compare original vs fully processed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fda782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process sample non-cancer test images\n",
    "for i, img_path in enumerate(non_cancer_test_files[:sample_size]):\n",
    "    processed_test_non_cancer=[]\n",
    "    print(f\"Processing non-cancer test image {i+1}/{sample_size}\")\n",
    "    processed_img = process_image(img_path)\n",
    "    if processed_img:\n",
    "        processed_test_non_cancer.append(processed_img)\n",
    "        visualize_processed_image(processed_img)  # Show all steps separately\n",
    "        visualize_fully_processed(processed_img)  # Compare original vs fully processed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6b9dfa",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "034f0622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_histogram(image, mask=None, bins=64):\n",
    "    \"\"\"Extract color histogram (192 features).\"\"\"\n",
    "    if mask is not None:\n",
    "        masked_image = image.copy()\n",
    "        masked_image[mask == 0] = 0\n",
    "    else:\n",
    "        masked_image = image\n",
    "    hist_r = np.histogram(masked_image[:, :, 0].ravel(), bins=bins, range=(0, 256))[0]\n",
    "    hist_g = np.histogram(masked_image[:, :, 1].ravel(), bins=bins, range=(0, 256))[0]\n",
    "    hist_b = np.histogram(masked_image[:, :, 2].ravel(), bins=bins, range=(0, 256))[0]\n",
    "    hist_r = hist_r / (hist_r.sum() + 1e-10)\n",
    "    hist_g = hist_g / (hist_g.sum() + 1e-10)\n",
    "    hist_b = hist_b / (hist_b.sum() + 1e-10)\n",
    "    return np.concatenate([hist_r, hist_g, hist_b])\n",
    "\n",
    "def extract_color_moments(image, mask=None):\n",
    "    \"\"\"Extract color moments in RGB (mean, variance, skewness, kurtosis; 12 features).\"\"\"\n",
    "    if mask is not None:\n",
    "        masked_image = image.copy()\n",
    "        masked_image[mask == 0] = 0\n",
    "    else:\n",
    "        masked_image = image\n",
    "    moments = []\n",
    "    for channel in range(3):\n",
    "        pixels = masked_image[:, :, channel].ravel()\n",
    "        pixels = pixels[pixels != 0] if mask is not None else pixels\n",
    "        if len(pixels) == 0:\n",
    "            moments.extend([0, 0, 0, 0])\n",
    "            continue\n",
    "        mean = np.mean(pixels)\n",
    "        variance = np.var(pixels)\n",
    "        skewness = skew(pixels, bias=False) if variance > 0 else 0\n",
    "        kurt = kurtosis(pixels, bias=False) if variance > 0 else 0\n",
    "        moments.extend([mean, variance, skewness, kurt])\n",
    "    return np.array(moments)\n",
    "\n",
    "def extract_hsv_stats(image, mask=None):\n",
    "    \"\"\"Extract mean and std of HSV channels (6 features).\"\"\"\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    if mask is not None:\n",
    "        masked_hsv = hsv_image.copy()\n",
    "        masked_hsv[mask == 0] = 0\n",
    "    else:\n",
    "        masked_hsv = hsv_image\n",
    "    stats = []\n",
    "    for channel in range(3):\n",
    "        pixels = masked_hsv[:, :, channel].ravel()\n",
    "        pixels = pixels[pixels != 0] if mask is not None else pixels\n",
    "        if len(pixels) == 0:\n",
    "            stats.extend([0, 0])\n",
    "            continue\n",
    "        mean = np.mean(pixels)\n",
    "        std = np.std(pixels)\n",
    "        stats.extend([mean, std])\n",
    "    return np.array(stats)\n",
    "\n",
    "def extract_lab_stats(image, mask=None):\n",
    "    \"\"\"Extract mean and std of LAB channels (6 features).\"\"\"\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "    if mask is not None:\n",
    "        masked_lab = lab_image.copy()\n",
    "        masked_lab[mask == 0] = 0\n",
    "    else:\n",
    "        masked_lab = lab_image\n",
    "    stats = []\n",
    "    for channel in range(3):\n",
    "        pixels = masked_lab[:, :, channel].ravel()\n",
    "        pixels = pixels[pixels != 0] if mask is not None else pixels\n",
    "        if len(pixels) == 0:\n",
    "            stats.extend([0, 0])\n",
    "            continue\n",
    "        mean = np.mean(pixels)\n",
    "        std = np.std(pixels)\n",
    "        stats.extend([mean, std])\n",
    "    return np.array(stats)\n",
    "\n",
    "def extract_haralick_and_stats(image, mask=None, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4]):\n",
    "    \"\"\"Extract Haralick features and intensity stats (mean, std, entropy, kurtosis; 17 features).\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    if mask is not None:\n",
    "        gray[mask == 0] = 0\n",
    "    pixels = gray.ravel()\n",
    "    pixels = pixels[pixels != 0] if mask is not None else pixels\n",
    "    if len(pixels) == 0:\n",
    "        stats = [0, 0, 0, 0]\n",
    "    else:\n",
    "        mean = np.mean(pixels)\n",
    "        std = np.std(pixels)\n",
    "        entropy = -np.sum([(p/pixels.sum()) * np.log2(p/pixels.sum() + 1e-10) \n",
    "                          for p in np.histogram(pixels, bins=256)[0] if p > 0])\n",
    "        kurt = kurtosis(pixels, bias=False) if std > 0 else 0\n",
    "        stats = [mean, std, entropy, kurt]\n",
    "    if mask is not None:\n",
    "        gray_for_glcm = gray.copy()\n",
    "        gray_for_glcm[mask == 0] = 0\n",
    "    else:\n",
    "        gray_for_glcm = gray\n",
    "    gray_for_glcm = gray_for_glcm.astype(np.uint8)\n",
    "    glcm = graycomatrix(gray_for_glcm, distances=distances, angles=angles, \n",
    "                        levels=256, symmetric=True, normed=True)\n",
    "    haralick_features = []\n",
    "    properties = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']\n",
    "    for prop in properties:\n",
    "        prop_values = graycoprops(glcm, prop).mean(axis=1).ravel()\n",
    "        haralick_features.extend(prop_values)\n",
    "    haralick_mahotas = mahotas.features.haralick(gray_for_glcm, return_mean=True)\n",
    "    extra_features = haralick_mahotas[[0, 1, 2, 3, 4, 8]]\n",
    "    return np.concatenate([haralick_features, extra_features, stats])\n",
    "\n",
    "def extract_wavelet_features(image, mask=None, wavelet='db1'):\n",
    "    \"\"\"Extract wavelet transform features (mean and std of coefficients; 6 features).\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    if mask is not None:\n",
    "        gray[mask == 0] = 0\n",
    "    \n",
    "    coeffs = dwt2(gray, wavelet)\n",
    "    cA, (cH, cV, cD) = coeffs  \n",
    "    features = []\n",
    "    for coeff in [cH, cV, cD]:  \n",
    "        pixels = coeff.ravel()\n",
    "        pixels = pixels[pixels != 0] if mask is not None else pixels\n",
    "        if len(pixels) == 0:\n",
    "            features.extend([0, 0])\n",
    "        else:\n",
    "            mean = np.mean(pixels)\n",
    "            std = np.std(pixels)\n",
    "            features.extend([mean, std])\n",
    "    return np.array(features)\n",
    "\n",
    "def extract_lbp(image, mask=None, radius=3, n_points=24):\n",
    "    \"\"\"Extract LBP histogram (26 features).\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    if mask is not None:\n",
    "        gray[mask == 0] = 0\n",
    "    lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), \n",
    "                          range=(0, n_points + 2), density=True)\n",
    "    return hist\n",
    "\n",
    "def extract_hu_moments(image, mask=None):\n",
    "    \"\"\"Extract Hu Moments (7 features).\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    if mask is not None:\n",
    "        gray[mask == 0] = 0\n",
    "    moments = cv2.moments(gray)\n",
    "    hu_moments = cv2.HuMoments(moments).ravel()\n",
    "    hu_moments = -np.sign(hu_moments) * np.log10(np.abs(hu_moments) + 1e-10)\n",
    "    return hu_moments\n",
    "\n",
    "def extract_diameter(image, mask=None):\n",
    "    \"\"\"Extract lesion diameter (1 feature).\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    if mask is None:\n",
    "        _, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    mask = mask.astype(np.uint8)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        diameter = 0\n",
    "    else:\n",
    "        contour = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        if len(contour) >= 5:  \n",
    "            ellipse = cv2.fitEllipse(contour)\n",
    "            diameter = max(ellipse[1])  \n",
    "        else:\n",
    "            \n",
    "            area = cv2.contourArea(contour)\n",
    "            diameter = 2 * np.sqrt(area / np.pi)\n",
    "    return np.array([diameter])\n",
    "\n",
    "def extract_circularity(image, mask=None):\n",
    "    \"\"\"Extract Circularity (1 feature).\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    if mask is None:\n",
    "        _, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    mask = mask.astype(np.uint8)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        circularity = 0\n",
    "    else:\n",
    "        contour = max(contours, key=cv2.contourArea)\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        area = cv2.contourArea(contour)\n",
    "        circularity = (4 * np.pi * area) / (perimeter ** 2 + 1e-10)\n",
    "    return np.array([circularity])\n",
    "\n",
    "def extract_asymmetry_and_border(image, mask=None):\n",
    "    \"\"\"Extract asymmetry and border irregularity (2 features).\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    if mask is None:\n",
    "        _, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    mask = mask.astype(np.uint8)\n",
    "    flipped = cv2.flip(mask, 1)\n",
    "    intersection = cv2.bitwise_and(mask, flipped)\n",
    "    union = cv2.bitwise_or(mask, flipped)\n",
    "    asymmetry_index = 1 - (np.sum(intersection) / (np.sum(union) + 1e-10))\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        border_irregularity = 0\n",
    "    else:\n",
    "        contour = max(contours, key=cv2.contourArea)\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        area = cv2.contourArea(contour)\n",
    "        border_irregularity = perimeter ** 2 / (4 * np.pi * area + 1e-10)\n",
    "    return np.array([asymmetry_index, border_irregularity])\n",
    "\n",
    "def normalize_features(features):\n",
    "    \"\"\"Normalize features to [0, 1] range.\"\"\"\n",
    "    if features.size == 0:\n",
    "        return features\n",
    "    min_val = np.min(features)\n",
    "    max_val = np.max(features)\n",
    "    if max_val == min_val:\n",
    "        return np.zeros_like(features)\n",
    "    return (features - min_val) / (max_val - min_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e776533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_features(image, mask=None):\n",
    "    \"\"\"Extract all features (color, texture, shape) and normalize.\"\"\"\n",
    "    color_hist = extract_color_histogram(image, mask, bins=64)  # 192 features\n",
    "    color_moments = extract_color_moments(image, mask)  # 12 features\n",
    "    hsv_stats = extract_hsv_stats(image, mask)  # 6 features\n",
    "    lab_stats = extract_lab_stats(image, mask)  # 6 features\n",
    "    haralick_stats = extract_haralick_and_stats(image, mask)  # 17 features\n",
    "    wavelet_features = extract_wavelet_features(image, mask)  # 6 features\n",
    "    lbp_hist = extract_lbp(image, mask, radius=3, n_points=24)  # 26 features\n",
    "    hu_moments = extract_hu_moments(image, mask)  # 7 features\n",
    "    diameter = extract_diameter(image, mask)  # 1 feature\n",
    "    circularity = extract_circularity(image, mask)  # 1 feature\n",
    "    asym_border = extract_asymmetry_and_border(image, mask)  # 2 features\n",
    "\n",
    "    features = np.concatenate([\n",
    "        color_hist,\n",
    "        color_moments,\n",
    "        hsv_stats,\n",
    "        lab_stats,\n",
    "        haralick_stats,\n",
    "        wavelet_features,\n",
    "        lbp_hist,\n",
    "        hu_moments,\n",
    "        diameter,\n",
    "        circularity,\n",
    "        asym_border\n",
    "    ])\n",
    "\n",
    "    features = normalize_features(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8bc1464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_features(train_files, test_files, train_labels, test_labels, output_path='features.npz'):\n",
    "    \"\"\"\n",
    "    Process all images, extract features, and save to NPZ file.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_files: List of training image file paths\n",
    "    - test_files: List of testing image file paths\n",
    "    - train_labels: List of training image labels\n",
    "    - test_labels: List of testing image labels\n",
    "    - output_path: Path to save the NPZ file\n",
    "    \"\"\"\n",
    "    print(f\"Processing {len(train_files)} training images and {len(test_files)} test images...\")\n",
    "    \n",
    "    \n",
    "    train_features = []\n",
    "    test_features = []\n",
    "    \n",
    "    \n",
    "    for i, img_path in enumerate(train_files):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processing training image {i+1}/{len(train_files)}\")\n",
    "        \n",
    "        \n",
    "        processed_img = process_image(img_path)\n",
    "        if processed_img:\n",
    "            \n",
    "            features = extract_all_features(processed_img['glare_removed'])\n",
    "            train_features.append(features)\n",
    "    \n",
    "    \n",
    "    for i, img_path in enumerate(test_files):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processing test image {i+1}/{len(test_files)}\")\n",
    "        \n",
    "        \n",
    "        processed_img = process_image(img_path)\n",
    "        if processed_img:\n",
    "            \n",
    "            features = extract_all_features(processed_img['glare_removed'])\n",
    "            test_features.append(features)\n",
    "    \n",
    "    \n",
    "    train_features = np.array(train_features)\n",
    "    test_features = np.array(test_features)\n",
    "    \n",
    "    np.savez(\n",
    "        output_path,\n",
    "        train_features=train_features,\n",
    "        test_features=test_features,\n",
    "        train_labels=np.array(train_labels[:len(train_features)]),\n",
    "        test_labels=np.array(test_labels[:len(test_features)])\n",
    "    )\n",
    "    \n",
    "    print(f\"Features extracted and saved to {output_path}\")\n",
    "    print(f\"Training features shape: {train_features.shape}\")\n",
    "    print(f\"Testing features shape: {test_features.shape}\")\n",
    "    \n",
    "    return train_features, test_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f0fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = \"kaggle/output/skin_cancer_features.npz\"\n",
    "if not os.path.exists(features_file):\n",
    "    os.makedirs(\"kaggle/output\", exist_ok=True)\n",
    "    \n",
    "    # Extract and save features\n",
    "    train_features, test_features = extract_and_save_features(\n",
    "        train_files, \n",
    "        test_files, \n",
    "        train_labels, \n",
    "        test_labels,\n",
    "        output_path=features_file\n",
    "    )\n",
    "else:\n",
    "    print(f\"Loading features from {features_file}\")\n",
    "    data = np.load(features_file)\n",
    "    train_features = data['train_features']\n",
    "    test_features = data['test_features']\n",
    "    train_labels = data['train_labels']\n",
    "    test_labels = data['test_labels']\n",
    "\n",
    "print(f\"Loaded features: {train_features.shape} training samples, {test_features.shape} test samples\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_features_scaled = scaler.fit_transform(train_features)\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "\n",
    "# Split training data for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_features_scaled, train_labels, test_size=0.2, random_state=42, stratify=train_labels\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(f\"Test set: {test_features_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98793fc",
   "metadata": {},
   "source": [
    "### Models setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99a4e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Define parameter grids\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['rbf', 'linear'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "# Grid search for SVM\n",
    "svm = SVC(probability=True)\n",
    "svm_grid = GridSearchCV(svm, svm_params, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "svm_grid.fit(X_train, y_train)\n",
    "best_svm = svm_grid.best_estimator_\n",
    "print(\"Best SVM params:\", svm_grid.best_params_)\n",
    "\n",
    "# Grid search for Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf_grid = GridSearchCV(rf, rf_params, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "print(\"Best Random Forest params:\", rf_grid.best_params_)\n",
    "\n",
    "# Create ensemble model\n",
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('svm', best_svm),\n",
    "    ('rf', best_rf)\n",
    "], voting='soft')  # soft voting uses predicted probabilities\n",
    "\n",
    "# Train the ensemble model\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_val_pred = ensemble.predict(X_val)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Validation Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Evaluate on test set\n",
    "y_test_pred = ensemble.predict(test_features_scaled)\n",
    "print(\"Test Accuracy:\", accuracy_score(test_labels, y_test_pred))\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(test_labels, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a06aae9",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f280652f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8122c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, title, ax):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, \n",
    "                xticklabels=['Non-Cancer', 'Cancer'], \n",
    "                yticklabels=['Non-Cancer', 'Cancer'], ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('True')\n",
    "\n",
    "# Function to plot ROC curve\n",
    "def plot_roc_curve(y_true, y_prob, title, ax):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    ax.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title(title)\n",
    "    ax.legend(loc='lower right')\n",
    "\n",
    "# Function to plot precision-recall curve\n",
    "def plot_precision_recall_curve(y_true, y_prob, title, ax):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
    "    avg_precision = average_precision_score(y_true, y_prob)\n",
    "    ax.plot(recall, precision, label=f'PR curve (AP = {avg_precision:.3f})')\n",
    "    ax.set_xlabel('Recall')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_title(title)\n",
    "    ax.legend(loc='lower left')\n",
    "\n",
    "# Evaluate model performance\n",
    "def evaluate_model(model, X_train, y_train, X_val, y_val, X_test, y_test, feature_names=None):\n",
    "    # Predictions and probabilities\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_val_prob = model.predict_proba(X_val)[:, 1]\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Print classification reports\n",
    "    print(\"Validation Classification Report:\")\n",
    "    print(classification_report(y_val, y_val_pred, target_names=['Non-Cancer', 'Cancer']))\n",
    "    print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.3f}\")\n",
    "    print(f\"Validation ROC-AUC: {auc(roc_curve(y_val, y_val_prob)[0], roc_curve(y_val, y_val_prob)[1]):.3f}\")\n",
    "    print(\"\\nTest Classification Report:\")\n",
    "    print(classification_report(y_test, y_test_pred, target_names=['Non-Cancer', 'Cancer']))\n",
    "    print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.3f}\")\n",
    "    print(f\"Test ROC-AUC: {auc(roc_curve(y_test, y_test_prob)[0], roc_curve(y_test, y_test_prob)[1]):.3f}\")\n",
    "\n",
    "    # Cross-validation\n",
    "    print(\"\\nPerforming 5-fold Cross-Validation on Training Data...\")\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    print(f\"Cross-Validation Accuracy: {np.mean(cv_scores):.3f} ± {np.std(cv_scores):.3f}\")\n",
    "\n",
    "    # Visualizations\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "    # Confusion matrices\n",
    "    plot_confusion_matrix(y_val, y_val_pred, \"Validation Confusion Matrix\", axes[0, 0])\n",
    "    plot_confusion_matrix(y_test, y_test_pred, \"Test Confusion Matrix\", axes[0, 1])\n",
    "\n",
    "    # ROC curves\n",
    "    plot_roc_curve(y_val, y_val_prob, \"Validation ROC Curve\", axes[0, 2])\n",
    "    plot_roc_curve(y_test, y_test_prob, \"Test ROC Curve\", axes[1, 2])\n",
    "\n",
    "    # Precision-Recall curves\n",
    "    plot_precision_recall_curve(y_val, y_val_prob, \"Validation Precision-Recall Curve\", axes[1, 0])\n",
    "    plot_precision_recall_curve(y_test, y_test_prob, \"Test Precision-Recall Curve\", axes[1, 1])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Feature importance (for Random Forest component)\n",
    "    if hasattr(model, 'estimators_') and isinstance(model.estimators_[1], RandomForestClassifier):\n",
    "        rf = model.estimators_[1]  # Random Forest is the second estimator in the VotingClassifier\n",
    "        importances = rf.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1][:10]  # Top 10 features\n",
    "        if feature_names is not None:\n",
    "            top_features = [feature_names[i] for i in indices]\n",
    "        else:\n",
    "            top_features = [f\"Feature {i}\" for i in indices]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x=importances[indices], y=top_features)\n",
    "        plt.title(\"Top 10 Feature Importances (Random Forest)\")\n",
    "        plt.xlabel(\"Importance\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Error analysis: Identify misclassified test samples\n",
    "    misclassified_idx = np.where(y_test != y_test_pred)[0]\n",
    "    print(f\"\\nNumber of misclassified test samples: {len(misclassified_idx)}\")\n",
    "    if len(misclassified_idx) > 0:\n",
    "        print(\"Sample misclassified test images (indices):\", misclassified_idx[:5])\n",
    "        # Optionally, visualize a few misclassified images\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        for i, idx in enumerate(misclassified_idx[:3]):  # Show up to 3 misclassified images\n",
    "            img = cv2.imread(test_files[idx])\n",
    "            if img is not None:\n",
    "                plt.subplot(1, 3, i+1)\n",
    "                plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "                plt.title(f\"True: {['Non-Cancer', 'Cancer'][y_test[idx]]}\\nPred: {['Non-Cancer', 'Cancer'][y_test_pred[idx]]}\")\n",
    "                plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "feature_names = (\n",
    "    [f\"Color_Hist_R_{i}\" for i in range(64)] +\n",
    "    [f\"Color_Hist_G_{i}\" for i in range(64)] +\n",
    "    [f\"Color_Hist_B_{i}\" for i in range(64)] +\n",
    "    [f\"Color_Moment_{m}_{c}\" for c in ['R', 'G', 'B'] for m in ['Mean', 'Variance', 'Skewness', 'Kurtosis']] +\n",
    "    [f\"HSV_{s}_{c}\" for c in ['H', 'S', 'V'] for s in ['Mean', 'Std']] +\n",
    "    [f\"LAB_{s}_{c}\" for c in ['L', 'A', 'B'] for s in ['Mean', 'Std']] +\n",
    "    [f\"Haralick_{p}_{i}\" for p in ['Contrast', 'Dissimilarity', 'Homogeneity', 'Energy', 'Correlation', 'ASM'] for i in range(1, 5)] +\n",
    "    [f\"Haralick_Mahotas_{i}\" for i in [0, 1, 2, 3, 4, 8]] +\n",
    "    ['Intensity_Mean', 'Intensity_Std', 'Intensity_Entropy', 'Intensity_Kurtosis'] +\n",
    "    [f\"Wavelet_{c}_{s}\" for c in ['H', 'V', 'D'] for s in ['Mean', 'Std']] +\n",
    "    [f\"LBP_{i}\" for i in range(26)] +\n",
    "    [f\"Hu_Moment_{i}\" for i in range(7)] +\n",
    "    ['Diameter', 'Circularity', 'Asymmetry', 'Border_Irregularity']\n",
    ")\n",
    "evaluate_model(ensemble, X_train, y_train, X_val, y_val, test_features_scaled, test_labels, feature_names=feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
